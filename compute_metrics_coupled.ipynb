{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "from typing import Dict, List, NamedTuple, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from scipy import sparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold, directory\n",
    "def get_folds(data_dir: str) -> List[Tuple[int, str]]:\n",
    "    folds = []\n",
    "    for dir in [f for f in Path(data_dir).iterdir() if f.is_dir()]:\n",
    "        dir_name = os.path.basename(dir)\n",
    "        if str(dir_name).isnumeric():\n",
    "            folds.append((int(dir_name), str(dir)))\n",
    "    folds.sort()\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 2d numpy array where 1. index is userId and 2. index is itemId, values are float ratings\n",
    "# returns 2d numpy array where 1. index is userId and 2. index is itemId, values are float ratings\n",
    "def load_data_old(data_dir: str, fold: int) -> np.ndarray:\n",
    "    #TODO: rewrite to consider test.csv\n",
    "    return np.load(os.path.join(data_dir, str(fold), \"mf_data.npy\"))\n",
    "\n",
    "def load_data(data_dir: str, fold: int) -> np.ndarray:\n",
    "    #TODO: rewrite to consider test.csv\n",
    "    #return np.load(os.path.join(data_dir, str(fold), \"mf_data.npy\"))\n",
    "    fullMatrix = np.load(os.path.join(data_dir, str(fold), \"mf_data.npy\"))\n",
    "    dataList = pd.read_csv(os.path.join(data_dir, str(fold), \"test.csv\"), sep=\",\", names=[\"uid\",\"oid\",\"val\"])\n",
    "    \n",
    "    dataMatrix = sparse.coo_matrix((dataList.val.tolist(), (dataList.uid.tolist(), dataList.oid.tolist())), shape = fullMatrix.shape)\n",
    "    dt =  dataMatrix.todense()\n",
    "    dt[dt < 4] = 0\n",
    "    dt[dt >= 4] = 1\n",
    "    return np.asarray(dt)\n",
    "    \n",
    "\n",
    "class Group(NamedTuple):\n",
    "    id: int\n",
    "    members: List[int]\n",
    "    \n",
    "class GroupWeights(NamedTuple):\n",
    "    id: int\n",
    "    members: List[float]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = load_data(\"data/ml1m\", 1)\n",
    "oldData = load_data_old(\"data/ml1m\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data must be in file formated with groupId, userid1, userid2...\n",
    "# separated by tabs\n",
    "def load_group_data(data_dir: str, group_type: str, group_size: int) -> List[Group]:\n",
    "    groups = []\n",
    "    filename = group_type + \"_group_\" + str(group_size)\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    with open(path) as group_file:\n",
    "        lines = group_file.readlines()\n",
    "        for line in lines:\n",
    "            items = line.replace('\\n', '').split(\"\\t\")\n",
    "            items = list(map(int, items))\n",
    "            groups.append(Group(items[0], items[1:]))\n",
    "            if len(items) < group_size + 1:\n",
    "                raise Exception(\"Group file invalid: \" + path)\n",
    "                                               \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_files(data_dir: str, fold: int, group: str, group_size: int) -> List[str]:\n",
    "    rec_path = os.path.join(data_dir, str(fold), group, str(group_size)) \n",
    "    return list([str(f) for f in Path(rec_path).iterdir() if f.is_file()])\n",
    "\n",
    "class AlgRecommendations(NamedTuple):\n",
    "    alg_name: str\n",
    "    # dict indexed by groupId\n",
    "    group_recommendations: Dict[int, List[int]] = {} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items are sorted from best to worst\n",
    "# returns list of tuples where first is the agreg name and second is dictionary of recommendations indexed by group id\n",
    "def load_agregated_recommendations(data_dir: str, fold: int, group: str, group_size: int) -> List[AlgRecommendations]:\n",
    "    whitelist = ['GFAR', '_AVG', 'FuzzyDHondtDirectOptimize_1', 'GreedyLM',  'FuzzyDHondt_1',  'SPGreedy',  'fai',  'xpo']\n",
    "    blacklist = \"rec_rel\"\n",
    "\n",
    "    files = get_recommendation_files(data_dir, fold, group, group_size)\n",
    "    r_files = []\n",
    "    for file in files:\n",
    "        for item in whitelist:\n",
    "            if item in file and blacklist not in file:\n",
    "                r_files.append(file)\n",
    "    #print(r_files)\n",
    "    #exit()    \n",
    "    \n",
    "    returnList = []\n",
    "    for file in r_files:\n",
    "        recommendationsMap = defaultdict(list) \n",
    "        with open(file) as recommendation_file:\n",
    "            lines = recommendation_file.readlines()\n",
    "            for line in lines:\n",
    "                items = line.replace('\\n', '').split(\"\\t\")[:2]\n",
    "                items = list(map(int, items))\n",
    "                group_id = items[0]\n",
    "                recommendationsMap[group_id].append(items[1])\n",
    "        alg_name = os.path.basename(file)\n",
    "        returnList.append(AlgRecommendations(alg_name, recommendationsMap))\n",
    "    return returnList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates discounted cumulative gain on the array of relevances\n",
    "def calculate_dcg(values):\n",
    "    values = np.array(values)\n",
    "    if values.size: #safety check\n",
    "        return np.sum(values / np.log2(np.arange(2, values.size + 2)))\n",
    "    return 0.0  \n",
    "\n",
    "#order items of user, cut best topk_size, calculate DCG of the cut\n",
    "#test_data = uidxoid matrix of ratings\n",
    "#topk_size = volume of items per user on which to calculate IDCG\n",
    "#return dictionary {userID:IDCG_value}\n",
    "def calculate_per_user_IDCG(test_data, topk_size):\n",
    "    users = range(test_data.shape[0])\n",
    "    idcg_per_user = {}\n",
    "    for user in users:        \n",
    "        per_user_items = test_data[user] \n",
    "        sorted_items = np.sort(per_user_items)[::-1]\n",
    "        sorted_items = sorted_items[0:20]\n",
    "        \n",
    "        idcg = calculate_dcg(sorted_items)\n",
    "        idcg_per_user[user] = idcg\n",
    "        \n",
    "        #print(sorted_items)\n",
    "        #print(idcg)\n",
    "        #exit()\n",
    "        \n",
    "    return idcg_per_user\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = range(test_data.shape[0])\n",
    "user = 0\n",
    "per_user_items = test_data[user]\n",
    "sorted_items = np.sort(per_user_items)[::-1]\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result(NamedTuple):\n",
    "    alg: str\n",
    "    group_id: str\n",
    "    user_id: int\n",
    "    metric: str\n",
    "    result: float\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(fold, test_data: np.ndarray, groups: List[Group],  alg_data: AlgRecommendations) -> List[Result]:\n",
    "    # test_data are triplets: user_id, item_id, and rating\n",
    "    #LP: test data is matrix user_id x item_id !!!!!! a ja si rikal, jakto ze ti to prirazeni funguje...\n",
    "    idcg_per_user = calculate_per_user_IDCG(test_data, 20)\n",
    "    #print(idcg_per_user)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    i = 0    \n",
    "    for group in groups:\n",
    "        #print(single_group_weights)\n",
    "        group_users_sum_ratings = []\n",
    "        group_users_ndcg_ratings = []\n",
    "        group_id = group.id \n",
    "        rec_for_group = alg_data.group_recommendations[group_id]\n",
    "        if len(rec_for_group) >0:\n",
    "          j = 0\n",
    "          for group_user_id in group.members:\n",
    "              user_sum = 0.0\n",
    "              user_list = []\n",
    "              for item_id in rec_for_group:\n",
    "                  rating = test_data[group_user_id, item_id]\n",
    "                  #print(group_user_id, item_id, rating)\n",
    "                  #print(type(test_data))\n",
    "                  #print(test_data.shape)\n",
    "                  #print(test_data[group_user_id])\n",
    "                  #exit()\n",
    "                  user_sum += rating\n",
    "                  user_list.append(rating)\n",
    "              dcg = calculate_dcg(user_list)\n",
    "              idcg = idcg_per_user[group_user_id] \n",
    "              if idcg != 0:\n",
    "                  ndcg = dcg / idcg\n",
    "              else:\n",
    "                  ndcg = 0\n",
    "              \n",
    "              group_users_sum_ratings.append(user_sum)\n",
    "              group_users_ndcg_ratings.append(ndcg)\n",
    "              j += 1\n",
    "              \n",
    "          group_users_mean_ratings = [i/len(rec_for_group) for i in group_users_sum_ratings] \n",
    "          \n",
    "  \n",
    "          for k in range(len(group_users_mean_ratings)):\n",
    "              results.append(Result(alg_data.alg_name, str(group_id)+\"_\"+str(fold), group.members[k], \"AR\", group_users_mean_ratings[k])   )\n",
    "              results.append(Result(alg_data.alg_name, str(group_id)+\"_\"+str(fold), group.members[k], \"nDCG\", group_users_ndcg_ratings[k])   )\n",
    "         \n",
    "          i += 1\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(groups: List[Group],  data_dir: str, fold: int, group: str, group_size: int) -> List[Result]:\n",
    "    algs_data = load_agregated_recommendations(data_dir, fold, group, group_size)\n",
    "    #print([i[0] for i in algs_data])\n",
    "    #exit()\n",
    "    test_data = load_data(data_dir, fold)\n",
    "    results = []\n",
    "    for alg_data in algs_data:\n",
    "        results.extend(compute_metrics(fold, test_data, groups,  alg_data))\n",
    "    #for result in results:\n",
    "    #    print(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_folder, group_type, group_size):\n",
    "    print(data_folder, group_type, group_size)\n",
    "    folds = get_folds(data_folder)\n",
    "    groups: List[Group] = load_group_data(data_folder, group_type, int(group_size))\n",
    "    #group_weights: List[GroupWeights] = load_group_weights_data(data_folder, group_type, int(group_size))\n",
    "    \n",
    "    results = []\n",
    "    for fold, _ in folds:\n",
    "        results.extend(process_fold(groups,  data_folder, fold, group_type, int(group_size)))\n",
    "\n",
    "        \n",
    "    algs = set(map(lambda x:x.alg, results))\n",
    "    metrics = set(map(lambda x:x.metric, results))\n",
    "    res = \"\"\n",
    "    for result in results:\n",
    "        result = [str(i) for i in result]\n",
    "        res += \",\".join(result)+\"\\n\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ml1m sim 2\n",
      "data/ml1m sim 3\n",
      "data/ml1m sim 4\n",
      "data/ml1m sim 8\n",
      "data/ml1m div 2\n",
      "data/ml1m div 3\n",
      "data/ml1m div 4\n",
      "data/ml1m div 8\n"
     ]
    }
   ],
   "source": [
    "f = open(\"results/result_raw_coupled\",\"w\")\n",
    "res = \"alg,group_id,user_id,metric,result\\n\"\n",
    "f.write(res)\n",
    "#for group_type in [\"sim\", \"div\", \"random\"]:\n",
    "#    for group_size in [\"2\",\"3\",\"4\",\"8\"]:\n",
    "for group_type in [\"sim\", \"div\"]:\n",
    "        for group_size in [\"2\",\"3\",\"4\",\"8\"]:\n",
    "            f2 = open(\"results/resultRaw_coupled_\"+group_type+\"_\"+group_size,\"w\")\n",
    "             \n",
    "            results = main(\"data/ml1m\", group_type, group_size)            \n",
    "            f.write(results)\n",
    "            f2.write(results)\n",
    "            #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
